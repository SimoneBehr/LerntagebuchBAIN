---
title: "VL6: Metadaten modellieren und Schnittstellen nutzen 1/2"
date: 2021-12-02
---

Für mich ist leider der Worst Case eingetroffen: Anfang Dezember war die ganze Familie krank und so verpasste ich nicht nur die Vorlesung am 2.12., sondern auch einen grossen Teil der Vorlesung am 3. 12., und kam dadurch mit dem Stoff sehr ins Hintertreffen. So konnte ich diese Vorlesung erst später über die Webex Aufnahme schauen.
<p>
Interessant fand ich die Frage zu OPAC und Katalog. Mir war nicht bewusst, dass manche Bibliotheken zwei Systeme verwenden, oft ein klassisches für die Verwaltung und ein moderneres für den Online-Katalog, da dieser bei den klassischen Systemen oft veraltet und wenig nutzerfreundlich ist. Da fehlt mir – wie schon so oft – die praktische Erfahrung. Ich stelle mir das doch eher ineffizient in der Handhabung vor. Auch der Unterschied zwischen OPAC (einem klassischen Online Public Access Catalogue) und einem Discovery-System (ein Marketing-Begriff für modernere OPACs mit einer überarbeiteten und vereinfachten User Experience) kannte ich nicht. Entsprechend spannend fand ich die Ausführungen von Felix Lohmeier.
<p>
Das Zwischenfazit mit Hilfe des altbekannten Schaubilds gab eine gute Übersicht über die Themen, die wir bereits behandelt haben, sowie einen Ausblick, was in den nächsten Lektionen noch ansteht. Nach meiner längeren "Zwangspause" in diesem Modul war dies eine willkommene Zusammenfassung, die mir den Wiedereinstieg sehr erleichterte.
<p>
Im Folgenden wurden drei Austausch- oder Übertragungsprotokolle für Metadaten vorgestellt. Z39.50 und SRU eignen sich vor allem für den Einzelabzug, also zum Beispiel, wenn gleichzeitig in mehreren Katalogen gesucht werden soll. In dieser Vorlesung arbeiten wir aber mit der OAI-PMH Schnittstelle, die ich ja nach der ersten Vorlesung bereits gegoogelt hatte und die sich vor allem für Gesamtdatenabzug eignet. Damit wollen wir nun also die Daten aus koha und ArchivesSpace "harvesten".
<p>
Die Endpoints waren zum Glück beide problemlos erreichbar, somit konnte ich mich direkt an die Installation von VuFind machen. Auch diese klappte auf Anhieb, worüber ich sehr froh bin. Ich hatte befürchtet, dass es zu Problemen kommt, welche ich dann mühsam per Mail hätte lösen müssen, da die Vorlesung ja schon eine Weile zurücklag.
<p>
Die Übung mit dem Harvesting klappte Dank Herrn Meyers detaillierter Erklärung auch problemlos. Ich konnte sowohl die Daten aus koha wie auch aus ArchivesSpace "ernten" und die entsprechenden Dateien auf meinem Rechner abspeichern.
<p>
Ziel des zweiten Teils der VL war es dann, die so erhaltenen Daten, die in verschiedenen Metastandards vorliegen (die Daten aus koha in MARC21-XML, diejenigen aus ArchivesSpace in EAD und die Daten aus DSpace im Standard Dublin Core) in einen einheitlichen Standard, nämlich MARC21-XML zu konvertieren. Dieses Vorgehen nennt sich Crosswalk. Mit Hilfe eines "Mappings" werden Regeln aufgestellt, welche Felder des ursprünglichen Formats welchen Feldern im Zielformat entsprechen. Herr Lohmeyer zeigte dies in einem Beispiel einleuchtend auf. Die Gesamtheit dieser Regeln stellt dann den "Crosswalk" dar, also den Zebrastreifen, auf welchem man sicher von einem zum anderen Standard kommt.
<p>
Wir nutzen dazu MarcEdit, eine Software, die seit 20 Jahren von einer einzelnen Person, Terry Reese, gepflegt wird (dies zeigt sich dann auch im eher altbackenen Logo und dem Foto des Hundes des Entwicklers, der helfend zur Seite stehen soll). Eine kleine Zusatzinformation, die ich doch sehr spannend fand, weil sie – wie Herr Lohmeier auch zu bedenken gab, zeigt, dass wir uns doch in einer sehr kleinen Branche in einem Nischenbereich bewegen.
<p>
Die Installation von MarcEdit war kein Problem. Zwar wurde beim ersten Aufstarten des Programms der Dateipfad, den man noch manuell ändern sollte, bei mir ganz anders aufgeführt. Nach einem Neustart konnte ich die in der Vorlesung angesprochene Änderung dann aber durchführen und die Daten entsprechend konvertieren.
